---
layout: post
title: MFCCs Feature Extraction
math: true
tags: basic
date: 2023-10-15 17:30 +0800
---
## Mel-Frequency Cepstral Coefficients(MFCCs) Feature Extraction
***Mel-Frequency Cepstral Coefficients(MFCCs)*** is one of main audio features, which is oftenly used in an Automatic Speech Recognition(ASR) system as input feature, mainly in GMM/DDN-HMM based ASR system while Fbank feature is used in modern ASR system such as end-to-end ASR system. Also, MFCC and Fbank are highly related, which means that MFCC can be obtained through a discrete consie transformer(DCT) step on Fbank features.

### How to extract mfcc from audio signal?  
MFCC feature extraction includes some saperate steps as follow:
- pre-emphasis 
- framing 
- windowing
- fast fourier transformation
- filter banks
- discrete consine transformation
- dynamic features
- 
### ***Signal Pre-emphasis***
the purpose of let signal getting pre-emphasis:

- Amplify the high frequency parts of audio signal, which have smaller magnitudes compared to lower frequencies
- Imporve the SNR (signal-to-noise) ratio of signal and reduce the affection of the noise

Here it is the algorithem, and its implementaion in python:

$$y(n) = x(n) - ax(n-1) , \hspace{0.5cm} (0.9<a<1.0)$$

``` python
import numpy as np
import soundfile as sf

def Emph_signal(x: np.arry, a=0.97)-> np.arry:
    y = np.append((x[0], x[1:] - a*z[:-1]))
    return y

wavfile = 'test.wav'
waveform, sample_rate = sf.read(wavfile)
emphasized_waveform = Emph_signal(waveform)
```
### visualization, comparison
```python
import matplotlib.pyplot as plt

plt.subplot(2,1,1)
plt.xlabel('Original Waveform')
plt.plot(waveform[:500])

plt.subplot(2,1,2)
plt.xlabel('After Emphasis')
plt.plot(emphasised_waveform[:500])
```
### ***Framing*** 
 After pre-emphasis, we need to cut the signal into short-time frames, typically lasting between 20 to 40 milliseconds.The reason behind this step is that frequencies in a signal change over time, so in most cases it doesn't make sense to do the Fourier transfom across entire signal in that we would lose the frequency contours of the signal over time. However, by analyzing these short, stable segments, we can more effectively capture and examine the speech's dynamic properties. Additionally, frames often overlap by about 50%, ensuring that no important information is missed and smoothing the transitions between segments. This overlap helps prevent discontinuities and ensures comprehensive analysis of speech stream.

### implementation in python
```python
sample_rate = 16000
frame_size = 400 / 16000 = 0.025 # if speech sampled in 16000hz 
frame_stride = 160 / 16000 = 0.01 
frame_length = frame_size * sample_rate
fram_step = frame_stride * sample_rate

signal_length = len(emphasized_waveform)
frame_length = int(round(frame_length))
frame_step = int(round(frame_step))
num_frames = 1 + int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step ))

pad_signal_length = num_frames * frame_step + frame_length
z = np.zeros((pad_signal_length - signal_length))
pad_signal = np.append(emphasized_waveform, z)
# slice the signal into frames, get the index of every single sample point
indexes = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames*frame_step, frame_step), (frame_length, 1)).T
frames = pad_siganl[indexes.astype(np.int32, copy=False)]
```
### ***Windowing*** 
 After slicing signal into frames, we apply a window function to each frame to prevent unwanted artifacts such as spectral leakage caused by the abrupt starts and ends of each frame, spicifically smoothing the edge of the frames, reducing sudden jumps in signal amplitude and minimizing the discontinuities at the frame borders.Generally, Hamming window is choosen in the term, which has following form:

  $$w[n] = 0.54 - 0.46cos(\frac{2n\pi}{N-1}),\hspace{0.5cm} 0 \leq n \leq N-1 $$

where, *N* is the length of Window, same as frame length, python implementation:

```python
frames *= np.hamming(frame_length)
```
### ***Fast Fourier transform (FFT)***
In this stage, we're gonna calculate the power of each frame using Discrete Fourier transformer(DFT), which also called Short Time Fourier Transformer(STFT). STFT plays vital rule in obtaining signal's power,signal can be transformed into frequency domain from time domain, that can bring us more informations for further studying the signal. FFT's arithmetic expresstion as follow:

$${X_k = \sum_{n=0}^{N-1} x_n \cdot e^{{-i2{\pi}kn}\over {N}}}$$

Where, *n = 0 ... N-1, N* is the length of signal, *x(n)* is the function of the signal. Above the expression, with a small extention:

$${X_{k+N} = \sum_{n=0}^{N-1} x_n \cdot e^{{-2i{\pi}\left({k+N}\right)n}\over{N}} = \sum_{n=0}^{N-1} x_n \cdot e^{{-2i{\pi}kn}\over{N}} \cdot e^{-2i{\pi}n}}$$

note that:

$$e^{-2i \pi n} = 1$$

therefore, we have :

$${X_{k+N} = \sum_{n=0}^{N-1} x_n \cdot e^{{-2i{\pi}\left({k+N}\right)n}\over{N}} = X_k}$$

so that for any integer *i*:

$$X_{k+i} \cdot _{N} = X{_k}_i $$

